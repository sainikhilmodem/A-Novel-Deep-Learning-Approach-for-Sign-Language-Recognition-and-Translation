# A-Novel-Deep-Learning-Approach-for-Sign-Language-Recognition-and-Translation

The Sign-to-Text project uses ResNet-50 for gesture classification, LSTM for sequential recognition, and 3D-CAM as an explainable AI (XAI) technique for model transparency. 
Achieved 98% accuracy.

The Sign Language Recognition project utilizes CNN and RNN architectures to classify sign language
gestures from video sequences. It incorporates Novelty with 3D Class Activation Mapping (3D CAM) as an
Explainable AI technique to highlight spatial-temporal regions influencing the modelâ€™s predictions. This approach
enhances the interpretability of deep learning models in sign language translation tasks.
